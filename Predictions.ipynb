{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_file = pd.read_csv('preprocessing_and_embeddings/cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = pd.read_csv('KMeans_clustering//sentiment_dictionary.csv')\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tfidf scores of words in every sentence, and replacing them with their associated tfidf weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weighting = final_file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serahverg/opt/miniconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/serahverg/opt/miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(file_weighting.text)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(file_weighting.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing words in sentences with their tfidf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 1.85 s, total: 27.7 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing words in sentences with their sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = file_weighting.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging both previous steps and getting the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.text, file_weighting.business_id,file_weighting.review_id]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'business_id','review_id']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "# replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.8838982981511367, 0.9008086114248798, 0.906...</td>\n",
       "      <td>[2.393876517559999, 2.009711825974233, 6.14987...</td>\n",
       "      <td>if you decide to eat here just be aware it is ...</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>81.663760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.9134369709351798, 0.947611305133934, 0.956...</td>\n",
       "      <td>[5.186615426306712, 1.5492577432740098, 7.6979...</td>\n",
       "      <td>this is the second time we tried turning_point...</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>VJxlBnJmCDIy8DFG0kjSow</td>\n",
       "      <td>265.887909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.956277369160358, 0.8909423442102302, 0.9476...</td>\n",
       "      <td>[3.299124774870296, 4.089742885936934, 1.54925...</td>\n",
       "      <td>the place is cute and the staff was very frien...</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>S6pQZQocMB1WHMjTRbt77A</td>\n",
       "      <td>100.572222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.8860928278216307, 0.931627456293174, 0.9290...</td>\n",
       "      <td>[10.414923613302891, 6.425692546252347, 1.8909...</td>\n",
       "      <td>we came on a saturday_morning after waiting a ...</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>WqgTKVqWVHDHjnjEsBvUgg</td>\n",
       "      <td>358.032481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9557299394709, -0.9019079713949786, 1.01417...</td>\n",
       "      <td>[5.504098941718361, 2.2049644267547137, 2.8955...</td>\n",
       "      <td>mediocre at best the decor is very nice and i ...</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>M0wzFFb7pefOPcxeRVbLag</td>\n",
       "      <td>548.101580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentiment_coeff  \\\n",
       "0  [0.8838982981511367, 0.9008086114248798, 0.906...   \n",
       "1  [-0.9134369709351798, 0.947611305133934, 0.956...   \n",
       "2  [0.956277369160358, 0.8909423442102302, 0.9476...   \n",
       "3  [0.8860928278216307, 0.931627456293174, 0.9290...   \n",
       "4  [0.9557299394709, -0.9019079713949786, 1.01417...   \n",
       "\n",
       "                                        tfidf_scores  \\\n",
       "0  [2.393876517559999, 2.009711825974233, 6.14987...   \n",
       "1  [5.186615426306712, 1.5492577432740098, 7.6979...   \n",
       "2  [3.299124774870296, 4.089742885936934, 1.54925...   \n",
       "3  [10.414923613302891, 6.425692546252347, 1.8909...   \n",
       "4  [5.504098941718361, 2.2049644267547137, 2.8955...   \n",
       "\n",
       "                                            sentence             business_id  \\\n",
       "0  if you decide to eat here just be aware it is ...  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  this is the second time we tried turning_point...  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "2  the place is cute and the staff was very frien...  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "3  we came on a saturday_morning after waiting a ...  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "4  mediocre at best the decor is very nice and i ...  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "\n",
       "                review_id  sentiment_rate  prediction  \n",
       "0  KU_O5udG6zpxOg-VcAEodg       81.663760           1  \n",
       "1  VJxlBnJmCDIy8DFG0kjSow      265.887909           1  \n",
       "2  S6pQZQocMB1WHMjTRbt77A      100.572222           1  \n",
       "3  WqgTKVqWVHDHjnjEsBvUgg      358.032481           1  \n",
       "4  M0wzFFb7pefOPcxeRVbLag      548.101580           1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporting model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_classes = replacement_df.prediction\n",
    "# y_test = replacement_df.sentiment\n",
    "\n",
    "# conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "# print('Confusion Matrix')\n",
    "# display(conf_matrix)\n",
    "\n",
    "# test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "# print('\\n \\n Scores')\n",
    "# scores = pd.DataFrame(data=[test_scores])\n",
    "# scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "# scores = scores.T\n",
    "# scores.columns = ['scores']\n",
    "# display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df.to_csv('nlp_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
